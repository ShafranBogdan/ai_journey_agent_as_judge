#!/usr/bin/env python3
"""
Simple Advanced Experiments for Agent-as-Judge
==============================================

–£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏:
- Data augmentation (–ø—Ä–æ—Å—Ç–æ–µ)
- Balanced classes (–ø—Ä–æ—Å—Ç–æ–µ)
- Different LoRA configurations (–ø—Ä–æ—Å—Ç–æ–µ)
- Basic ensemble (–ø—Ä–æ—Å—Ç–æ–µ)

–£–±—Ä–∞–Ω—ã –≤—Å–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ - —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—Ç–∞—é—â–∏–µ –∏–¥–µ–∏.
–û—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Å—Ç–∏–ª–µ Agent_as_judge_finetune.ipynb
"""

import pandas as pd
import numpy as np
import torch
import random
import re
from datasets import Dataset
from unsloth import FastModel
from unsloth.chat_templates import get_chat_template, train_on_responses_only
from trl import SFTTrainer, SFTConfig
import warnings
warnings.filterwarnings("ignore")

# –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –∏–º–ø–æ—Ä—Ç—ã
try:
    import optuna
    OPTUNA_AVAILABLE = True
    print("‚úÖ Optuna –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è hyperparameter optimization")
except ImportError:
    OPTUNA_AVAILABLE = False
    print("‚ö†Ô∏è Optuna –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install optuna")

from collections import Counter
import json
import os


def set_seed(seed=42):
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏"""
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)


def simple_augment_data(df, augment_ratio=0.3):
    """–ü—Ä–æ—Å—Ç–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    print(f"üîÑ –ü—Ä–∏–º–µ–Ω—è–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö (ratio={augment_ratio})...")
    
    replacements = {
        "–∑–∞–¥–∞–Ω–∏–µ –¥–ª—è –æ—Ü–µ–Ω–∫–∏": ["–∑–∞–¥–∞—á–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", "–ø—Ä–∏–º–µ—Ä –¥–ª—è –æ—Ü–µ–Ω–∫–∏"],
        "—ç—Ç–∞–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç": ["–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç", "–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç"],
        "–æ—Ç–≤–µ—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏": ["–ø—Ä–æ–≤–µ—Ä—è–µ–º—ã–π –æ—Ç–≤–µ—Ç", "–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–π –æ—Ç–≤–µ—Ç"],
        "–∫—Ä–∏—Ç–µ—Ä–∏–π –æ—Ü–µ–Ω–∫–∏": ["–ø–∞—Ä–∞–º–µ—Ç—Ä –æ—Ü–µ–Ω–∫–∏", "–ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞"]
    }
    
    augmented_rows = []
    num_to_augment = int(len(df) * augment_ratio)
    sample_indices = random.sample(range(len(df)), min(num_to_augment, len(df)))
    
    for idx in sample_indices:
        row = df.iloc[idx].copy()
        prompt = row['prompt']
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–º–µ–Ω—ã
        for original, variants in replacements.items():
            if original.lower() in prompt.lower():
                new_phrase = random.choice(variants)
                prompt = prompt.lower().replace(original.lower(), new_phrase.lower())
        
        # –ù–µ–±–æ–ª—å—à–∏–µ –≤–∞—Ä–∏–∞—Ü–∏–∏
        if random.random() < 0.5:
            prompt = prompt.replace("–≤—ã–ø–æ–ª–Ω–∏", "–≤—ã–ø–æ–ª–Ω–∏—Ç–µ")
            prompt = prompt.replace("–Ω–∞–π–¥–∏", "–Ω–∞–π–¥–∏—Ç–µ")
        
        row['prompt'] = prompt
        augmented_rows.append(row)
    
    augmented_df = pd.concat([df, pd.DataFrame(augmented_rows)], ignore_index=True)
    print(f"–ü–æ—Å–ª–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {len(augmented_df)} –ø—Ä–∏–º–µ—Ä–æ–≤ (+{len(augmented_rows)} –Ω–æ–≤—ã—Ö)")
    
    return augmented_df.sample(frac=1, random_state=42)


def balance_classes(df, method="undersample"):
    """–ü—Ä–æ—Å—Ç–∞—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤"""
    print(f"‚öñÔ∏è –ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã –º–µ—Ç–æ–¥–æ–º '{method}'...")
    
    score_counts = df['score'].value_counts()
    print("–î–æ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏:", score_counts.sort_index().to_dict())
    
    if method == "undersample":
        min_count = score_counts.min()
        balanced_dfs = []
        
        for score in df['score'].unique():
            score_df = df[df['score'] == score]
            if len(score_df) > min_count:
                score_df = score_df.sample(n=min_count, random_state=42)
            balanced_dfs.append(score_df)
        
        balanced_df = pd.concat(balanced_dfs, ignore_index=True)
        
    elif method == "oversample":
        max_count = score_counts.max()
        balanced_dfs = []
        
        for score in df['score'].unique():
            score_df = df[df['score'] == score]
            while len(score_df) < max_count:
                to_add = min(max_count - len(score_df), len(df[df['score'] == score]))
                extra = df[df['score'] == score].sample(n=to_add, replace=True, random_state=42)
                score_df = pd.concat([score_df, extra], ignore_index=True)
            balanced_dfs.append(score_df)
        
        balanced_df = pd.concat(balanced_dfs, ignore_index=True)
    else:
        balanced_df = df
    
    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)
    
    print("–ü–æ—Å–ª–µ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏:", balanced_df['score'].value_counts().sort_index().to_dict())
    return balanced_df


def setup_model_simple(model_name="Qwen/Qwen3-0.6B", max_seq_length=1024, lora_r=16):
    """–ü—Ä–æ—Å—Ç–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏"""
    print(f"ü§ñ –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å {model_name} —Å LoRA rank={lora_r}...")
    
    model, tokenizer = FastModel.from_pretrained(
        model_name=model_name,
        max_seq_length=max_seq_length,
        load_in_4bit=True,
        dtype=None
    )
    
    model = FastModel.get_peft_model(
        model,
        r=lora_r,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj", 
                       "gate_proj", "up_proj", "down_proj"],
        lora_alpha=32,
        lora_dropout=0.1,
        bias="none",
        use_gradient_checkpointing="unsloth",
        random_state=42,
    )
    
    tokenizer = get_chat_template(tokenizer, chat_template="qwen-3")
    print("‚úÖ –ú–æ–¥–µ–ª—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞")
    
    return model, tokenizer


def prepare_dataset_simple(df, tokenizer, test_size=0.2):
    """–ü—Ä–æ—Å—Ç–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    print("üìù –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
    
    dataset = Dataset.from_pandas(df[['prompt', 'score']])
    
    def format_examples(examples):
        messages = [
            [{'role': 'user', 'content': prompt}, 
             {'role': 'assistant', 'content': str(int(score))}]
            for prompt, score in zip(examples['prompt'], examples['score'])
        ]
        
        texts = [
            tokenizer.apply_chat_template(
                message, tokenize=False, add_generation_prompt=False
            ) 
            for message in messages
        ]
        
        return {"text": texts}
    
    dataset = dataset.map(format_examples, batched=True)
    dataset = dataset.train_test_split(test_size=test_size, seed=42)
    
    print(f"–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(dataset['train'])}")
    print(f"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(dataset['test'])}")
    
    return dataset


def train_simple(model, tokenizer, dataset, output_dir, epochs=2, batch_size=2, learning_rate=2e-4):
    """–ü—Ä–æ—Å—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ"""
    print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {epochs} —ç–ø–æ—Ö...")
    
    trainer = SFTTrainer(
        model=model,
        tokenizer=tokenizer,
        train_dataset=dataset['train'],
        eval_dataset=dataset['test'],
        args=SFTConfig(
            dataset_text_field="text",
            per_device_train_batch_size=batch_size,
            gradient_accumulation_steps=2,
            warmup_ratio=0.05,
            num_train_epochs=epochs,
            learning_rate=learning_rate,
            logging_steps=10,
            optim="adamw_torch",
            weight_decay=0.01,
            lr_scheduler_type="linear",
            seed=42,
            output_dir=output_dir,
            # –£–±–∏—Ä–∞–µ–º evaluation_strategy - –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏—è—Ö SFTConfig
            # evaluation_strategy="steps",
            # eval_steps=50,
            save_steps=100,
            save_total_limit=2,
            report_to="none",
        ),
    )
    
    # –û–±—É—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Ç–≤–µ—Ç–∞—Ö - –ò–°–ü–†–ê–í–õ–ï–ù–û —Å –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ–º –º—É–ª—å—Ç–∏–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
    trainer = train_on_responses_only(
        trainer,
        instruction_part="<|im_start|>user\n",
        response_part="<|im_start|>assistant\n",
        num_proc=1  # –û—Ç–∫–ª—é—á–∞–µ–º –º—É–ª—å—Ç–∏–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–æ–∫
    )
    
    trainer.train()
    trainer.save_model()
    
    print(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {output_dir}")
    return trainer


def simple_inference(model, tokenizer, test_prompts, max_tokens=10):
    """–ü—Ä–æ—Å—Ç–æ–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏"""
    results = []
    
    model.eval()
    with torch.no_grad():
        for prompt in test_prompts:
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∫ –≤ run.py
            messages = [{"role": "user", "content": prompt}]
            formatted = tokenizer.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=True, enable_thinking=False
            )
            
            # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
            inputs = tokenizer(formatted, return_tensors="pt").to(model.device)
            outputs = model.generate(
                **inputs, max_new_tokens=max_tokens, temperature=0.0, do_sample=False
            )
            
            # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
            generated = tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True)
            score = int(generated[0]) if generated and generated[0].isdigit() else 0
            results.append(score)
    
    return results


def optuna_objective(trial, train_df, val_df):
    """Objective function –¥–ª—è Optuna –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    if not OPTUNA_AVAILABLE:
        raise ImportError("Optuna –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    lora_r = trial.suggest_categorical('lora_r', [8, 16, 32, 64])
    lora_alpha = trial.suggest_categorical('lora_alpha', [16, 32, 64, 128])
    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-4, log=True)
    batch_size = trial.suggest_categorical('batch_size', [1, 2, 4])
    epochs = trial.suggest_int('epochs', 1, 3)
    
    try:
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        model, tokenizer = FastModel.from_pretrained(
            model_name="Qwen/Qwen3-0.6B",
            max_seq_length=1024,
            load_in_4bit=True,
            dtype=None
        )
        
        model = FastModel.get_peft_model(
            model,
            r=lora_r,
            target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
            lora_alpha=lora_alpha,
            lora_dropout=0.1,
            bias="none",
            use_gradient_checkpointing="unsloth",
            random_state=42,
        )
        
        tokenizer = get_chat_template(tokenizer, chat_template="qwen-3")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        train_dataset = prepare_dataset_simple(train_df, tokenizer, test_size=0.0)['train']
        val_dataset = prepare_dataset_simple(val_df, tokenizer, test_size=0.0)['train']
        
        # –û–±—É—á–µ–Ω–∏–µ
        trainer = SFTTrainer(
            model=model,
            tokenizer=tokenizer,
            train_dataset=train_dataset,
            eval_dataset=None,  # –£–±–∏—Ä–∞–µ–º eval –≤–æ –≤—Ä–µ–º—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            args=SFTConfig(
                dataset_text_field="text",
                per_device_train_batch_size=batch_size,
                gradient_accumulation_steps=2,
                warmup_ratio=0.05,
                num_train_epochs=epochs,
                learning_rate=learning_rate,
                logging_steps=100,
                optim="adamw_torch",
                weight_decay=0.01,
                lr_scheduler_type="linear",
                seed=42,
                output_dir=f"./optuna_trial_{trial.number}",
                save_strategy="no",  # –ù–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                report_to="none",
            ),
        )
        
        trainer = train_on_responses_only(
            trainer,
            instruction_part="<|im_start|>user\n",
            response_part="<|im_start|>assistant\n",
        )
        
        trainer.train()
        
        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        val_predictions = simple_inference(model, tokenizer, val_df['prompt'].tolist())
        val_true = val_df['score'].tolist()
        
        # –ü—Ä–æ—Å—Ç–∞—è –º–µ—Ç—Ä–∏–∫–∞ - accuracy
        accuracy = sum(p == t for p, t in zip(val_predictions, val_true)) / len(val_true)
        
        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        del model, tokenizer, trainer
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return accuracy
        
    except Exception as e:
        print(f"Trial {trial.number} failed: {e}")
        return 0.0


def run_optuna_optimization(n_trials=20):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç Optuna –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
    if not OPTUNA_AVAILABLE:
        print("‚ùå Optuna –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é")
        return None
    
    print("\n" + "="*60)
    print("üéØ OPTUNA HYPERPARAMETER OPTIMIZATION")
    print("="*60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = pd.read_csv("aij_judge_task_1_train.csv")
    sample_df = df.sample(n=500, random_state=42)  # –ú–∞–ª–µ–Ω—å–∫–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ train/val –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    train_df = sample_df.iloc[:400]
    val_df = sample_df.iloc[400:]
    
    print(f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞ {len(train_df)} train + {len(val_df)} val –ø—Ä–∏–º–µ—Ä–∞—Ö")
    print(f"–ó–∞–ø—É—Å–∫–∞–µ–º {n_trials} trials...")
    
    # –°–æ–∑–¥–∞–µ–º study
    study = optuna.create_study(direction='maximize', study_name="agent_judge_hp_opt")
    
    # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º
    study.optimize(
        lambda trial: optuna_objective(trial, train_df, val_df), 
        n_trials=n_trials,
        timeout=1800,  # 30 –º–∏–Ω—É—Ç –º–∞–∫—Å–∏–º—É–º
        n_jobs=1  # –ë–µ–∑ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    )
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüèÜ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (accuracy={study.best_value:.4f}):")
    for key, value in study.best_params.items():
        print(f"  {key}: {value}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    with open("optuna_best_params.json", "w") as f:
        json.dump({
            "best_params": study.best_params,
            "best_value": study.best_value,
            "n_trials": len(study.trials)
        }, f, indent=2)
    
    return study.best_params


class SimpleEnsemble:
    """–ü—Ä–æ—Å—Ç–æ–π ensemble –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self):
        self.models = []
        self.tokenizers = []
        self.model_weights = []
    
    def add_model(self, model, tokenizer, weight=1.0):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å –≤ ensemble"""
        self.models.append(model)
        self.tokenizers.append(tokenizer)
        self.model_weights.append(weight)
        print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å –≤ ensemble (–≤—Å–µ–≥–æ: {len(self.models)})")
    
    def predict(self, test_prompts, max_tokens=10):
        """Ensemble –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
        if not self.models:
            raise ValueError("–ù–µ—Ç –º–æ–¥–µ–ª–µ–π –≤ ensemble")
        
        all_predictions = []
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
        for i, (model, tokenizer, weight) in enumerate(zip(self.models, self.tokenizers, self.model_weights)):
            print(f"üîÆ –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –º–æ–¥–µ–ª–∏ {i+1}/{len(self.models)}...")
            
            model_preds = simple_inference(model, tokenizer, test_prompts, max_tokens)
            all_predictions.append(model_preds)
        
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–º–æ–¥–∞/–≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ –ø–æ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤—É)
        final_predictions = []
        
        for i in range(len(test_prompts)):
            # –°–æ–±–∏—Ä–∞–µ–º –≥–æ–ª–æ—Å–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞
            votes = []
            for j, model_preds in enumerate(all_predictions):
                model_pred = model_preds[i]
                weight = int(self.model_weights[j])
                votes.extend([model_pred] * weight)
            
            # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–π –æ—Ç–≤–µ—Ç
            vote_counts = Counter(votes)
            majority_vote = vote_counts.most_common(1)[0][0]
            final_predictions.append(majority_vote)
        
        return final_predictions
    
    def save_ensemble(self, output_dir):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ ensemble"""
        os.makedirs(output_dir, exist_ok=True)
        
        for i, (model, tokenizer) in enumerate(zip(self.models, self.tokenizers)):
            model_dir = os.path.join(output_dir, f"model_{i}")
            model.save_pretrained(model_dir)
            tokenizer.save_pretrained(model_dir)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        meta = {
            "num_models": len(self.models),
            "model_weights": self.model_weights
        }
        with open(os.path.join(output_dir, "ensemble_meta.json"), "w") as f:
            json.dump(meta, f, indent=2)
        
        print(f"üíæ Ensemble —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_dir}")


def create_ensemble_models():
    """–°–æ–∑–¥–∞–µ—Ç ensemble –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π"""
    print("\n" + "="*60)
    print("üé≠ CREATING ENSEMBLE MODELS")
    print("="*60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = pd.read_csv("aij_judge_task_1_train.csv")
    sample_df = df.sample(n=1000, random_state=42)
    
    ensemble = SimpleEnsemble()
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    configs = [
        {"lora_r": 16, "lr": 2e-4, "epochs": 2, "name": "conservative"},
        {"lora_r": 32, "lr": 1.5e-4, "epochs": 3, "name": "balanced"}, 
        {"lora_r": 64, "lr": 1e-4, "epochs": 2, "name": "expressive"}
    ]
    
    for i, config in enumerate(configs):
        print(f"\nüîÑ –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å {i+1}: {config['name']}")
        set_seed(42 + i)  # –†–∞–∑–Ω—ã–µ seeds –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
        
        try:
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏
            model, tokenizer = setup_model_simple(lora_r=config["lora_r"])
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (—Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è)
            dataset = prepare_dataset_simple(sample_df, tokenizer, test_size=0.1 + i*0.05)
            
            # –û–±—É—á–µ–Ω–∏–µ
            trainer = train_simple(
                model, tokenizer, dataset, f"./ensemble_model_{i}", 
                epochs=config["epochs"], learning_rate=config["lr"]
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ ensemble —Å –≤–µ—Å–æ–º
            weight = 1.0 if config["name"] != "balanced" else 1.5  # –ë–æ–ª—å—à–∏–π –≤–µ—Å —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            ensemble.add_model(model, tokenizer, weight)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–æ–¥–µ–ª–∏ {i+1}: {e}")
            continue
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º ensemble
    if ensemble.models:
        ensemble.save_ensemble("./final_ensemble")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º ensemble
        test_sample = sample_df.head(20)
        ensemble_preds = ensemble.predict(test_sample['prompt'].tolist())
        
        print(f"\nüìä –¢–µ—Å—Ç ensemble –Ω–∞ {len(test_sample)} –ø—Ä–∏–º–µ—Ä–∞—Ö:")
        for i, (true_score, pred_score) in enumerate(zip(test_sample['score'], ensemble_preds)):
            print(f"  {i+1}: True={true_score}, Pred={pred_score}")
        
        accuracy = sum(t == p for t, p in zip(test_sample['score'], ensemble_preds)) / len(test_sample)
        print(f"Accuracy: {accuracy:.3f}")
    
    return ensemble


def run_experiment_5_data_augmentation():
    """–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 5: Data Augmentation (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)"""
    print("\n" + "="*60)
    print("üß™ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 5: Simple Data Augmentation")
    print("="*60)
    
    set_seed(42)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = pd.read_csv("aij_judge_task_1_train.csv")
    print(f"–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(df)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    # –ë–µ—Ä–µ–º –≤—ã–±–æ—Ä–∫—É –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    sample_df = df.sample(n=1500, random_state=42)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é
    augmented_df = simple_augment_data(sample_df, augment_ratio=0.4)
    
    # –ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ–º
    final_df = balance_classes(augmented_df, method="undersample")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏
    model, tokenizer = setup_model_simple(lora_r=32)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    dataset = prepare_dataset_simple(final_df, tokenizer)
    
    # –û–±—É—á–µ–Ω–∏–µ
    trainer = train_simple(
        model, tokenizer, dataset, "./exp5_augmented", 
        epochs=3, learning_rate=2e-4
    )
    
    return trainer


def run_experiment_6_balanced():
    """–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 6: Balanced Classes (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)"""
    print("\n" + "="*60)
    print("üß™ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 6: Simple Balanced Classes")
    print("="*60)
    
    set_seed(42)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –±–∞–ª–∞–Ω—Å–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    df = pd.read_csv("aij_judge_task_1_train.csv")
    sample_df = df.sample(n=2000, random_state=42)
    balanced_df = balance_classes(sample_df, method="undersample")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏
    model, tokenizer = setup_model_simple(lora_r=16)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    dataset = prepare_dataset_simple(balanced_df, tokenizer)
    
    # –û–±—É—á–µ–Ω–∏–µ
    trainer = train_simple(
        model, tokenizer, dataset, "./exp6_balanced", 
        epochs=3, learning_rate=1.5e-4
    )
    
    return trainer


def run_experiment_7_ranks():
    """–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 7: Different LoRA Ranks (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)"""
    print("\n" + "="*60)
    print("üß™ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 7: Simple LoRA Ranks")
    print("="*60)
    
    results = {}
    df = pd.read_csv("aij_judge_task_1_train.csv")
    sample_df = df.sample(n=800, random_state=42)
    
    for rank in [8, 16, 32]:  # –£–ø—Ä–æ—â–∞–µ–º —Å–ø–∏—Å–æ–∫
        print(f"\nüîÑ –¢–µ—Å—Ç–∏—Ä—É–µ–º LoRA rank = {rank}")
        set_seed(42)
        
        model, tokenizer = setup_model_simple(lora_r=rank)
        dataset = prepare_dataset_simple(sample_df, tokenizer)
        
        trainer = train_simple(
            model, tokenizer, dataset, f"./exp7_rank_{rank}", 
            epochs=2, batch_size=4
        )
        
        results[f"rank_{rank}"] = trainer
        
        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        del model, tokenizer, trainer
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    return results


def run_experiment_8_optuna():
    """–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 8: Optuna Hyperparameter Optimization"""
    if not OPTUNA_AVAILABLE:
        print("‚ùå Optuna –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º...")
        import subprocess
        subprocess.check_call(["pip", "install", "optuna"])
        try:
            import optuna
            print("‚úÖ Optuna —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        except ImportError:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Optuna")
            return None
    
    best_params = run_optuna_optimization(n_trials=15)
    
    if best_params:
        print("\nüîÑ –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏...")
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        df = pd.read_csv("aij_judge_task_1_train.csv")
        sample_df = df.sample(n=1500, random_state=42)
        
        model, tokenizer = setup_model_simple(lora_r=best_params.get('lora_r', 32))
        dataset = prepare_dataset_simple(sample_df, tokenizer)
        
        trainer = train_simple(
            model, tokenizer, dataset, "./exp8_optuna_best",
            epochs=best_params.get('epochs', 3),
            batch_size=best_params.get('batch_size', 2),
            learning_rate=best_params.get('learning_rate', 2e-4)
        )
        
        return trainer
    
    return None


def run_experiment_9_ensemble():
    """–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 9: Ensemble Models"""
    print("\n" + "="*60)
    print("üß™ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 9: Ensemble Models")
    print("="*60)
    
    return create_ensemble_models()


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è - –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã"""
    print("üöÄ –ü–†–û–î–í–ò–ù–£–¢–´–ï –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–´ –° OPTUNA –ò ENSEMBLE")
    print("="*60)
    
    experiments = [
        ("5", "Data Augmentation", run_experiment_5_data_augmentation),
        ("6", "Balanced Classes", run_experiment_6_balanced), 
        ("7", "LoRA Ranks", run_experiment_7_ranks),
        ("8", "Optuna Optimization", run_experiment_8_optuna),
        ("9", "Ensemble Models", run_experiment_9_ensemble),
    ]
    
    results = {}
    
    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    print("\n–í—ã–±–µ—Ä–∏—Ç–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –¥–ª—è –∑–∞–ø—É—Å–∫–∞:")
    for exp_id, exp_name, _ in experiments:
        print(f"  {exp_id} - {exp_name}")
    print("  all - –í—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã")
    print("  advanced - –¢–æ–ª—å–∫–æ Optuna + Ensemble (8,9)")
    
    choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä(–∞) —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é –∏–ª–∏ 'all'/'advanced': ").strip()
    
    if choice == "all":
        selected_experiments = experiments
    elif choice == "advanced":
        selected_experiments = [exp for exp in experiments if exp[0] in ["8", "9"]]
    else:
        selected_ids = [x.strip() for x in choice.split(",")]
        selected_experiments = [exp for exp in experiments if exp[0] in selected_ids]
    
    print(f"\nüéØ –ó–∞–ø—É—Å–∫–∞–µ–º {len(selected_experiments)} —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤...")
    
    for exp_id, exp_name, exp_func in selected_experiments:
        try:
            print(f"\n‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç {exp_id}: {exp_name}")
            result = exp_func()
            results[exp_id] = result
            print(f"‚úÖ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç {exp_id} –∑–∞–≤–µ—Ä—à–µ–Ω")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ {exp_id}: {e}")
            import traceback
            traceback.print_exc()
    
    print("\nüéØ –í—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
    print(f"–£—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {len(results)} –∏–∑ {len(selected_experiments)}")
    
    if results:
        print("\nüìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print("- –û–±—ã—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ exp5_*, exp6_*, exp7_*")
        if "8" in results and results["8"]:
            print("- –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã Optuna —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ optuna_best_params.json")
            print("- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ exp8_optuna_best/")
        if "9" in results and results["9"]:
            print("- Ensemble –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ final_ensemble/")
            print("- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ ensemble –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞!")
    
    print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print("1. –î–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ ensemble –∏–ª–∏ –º–æ–¥–µ–ª—å –∏–∑ exp8_optuna_best")
    print("2. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∫–∞–∫ aij_qwen_0.6b –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å run.py")
    print("3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ optuna_best_params.json –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")


def create_run_py_compatible_model():
    """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å —Å–æ–≤–º–µ—Å—Ç–∏–º—É—é —Å run.py –∏–∑ –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    print("üîÑ –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è run.py...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
    models_to_check = [
        ("exp8_optuna_best", "Optuna-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å"),
        ("exp6_balanced", "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å"),
        ("exp5_augmented", "–ê—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å"),
    ]
    
    best_model_dir = None
    for model_dir, description in models_to_check:
        if os.path.exists(model_dir):
            best_model_dir = model_dir
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ {description} –≤ {model_dir}")
            break
    
    if best_model_dir:
        print(f"üìÅ –ö–æ–ø–∏—Ä—É–µ–º {best_model_dir} –≤ aij_qwen_0.6b –¥–ª—è run.py...")
        import shutil
        
        if os.path.exists("aij_qwen_0.6b"):
            shutil.rmtree("aij_qwen_0.6b")
        shutil.copytree(best_model_dir, "aij_qwen_0.6b")
        
        print("‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å run.py!")
        print("–¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å: python run.py --test_path test.csv --pred_path predictions.csv")
    else:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã.")


if __name__ == "__main__":
    main()