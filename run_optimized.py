#!/usr/bin/env python3
"""
Optimized Run Script for Agent-as-Judge Competition
===================================================

–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–∞–±–º–∏—Ç–∞ –≤ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–∏.
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å –∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç
—Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞.
"""

import os
import pandas as pd
import numpy as np
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from vllm import LLM, SamplingParams
from argparse import ArgumentParser
import re
import json
from pathlib import Path
import warnings
warnings.filterwarnings("ignore")


def find_best_model():
    """–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    
    # –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
    model_candidates = [
        "models/exp4_enhanced_lora/unsloth_model",
        "models/exp2_balanced_lora/unsloth_model", 
        "models/exp3_full_finetuning/unsloth_model",
        "models/exp1_baseline_lora/unsloth_model",
        "baseline/aij_qwen_0.6b",  # Fallback
    ]
    
    for model_path in model_candidates:
        if os.path.exists(model_path):
            print(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å: {model_path}")
            return model_path
    
    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º baseline
    print("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º baseline")
    return "aij_qwen_0.6b"


def enhanced_prompt_formatting(prompt: str) -> str:
    """–£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è"""
    
    # –î–æ–±–∞–≤–ª—è–µ–º —á–µ—Ç–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    system_instruction = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-—Å—É–¥—å—è, –æ—Ü–µ–Ω–∏–≤–∞—é—â–∏–π –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. 

–í–ê–ñ–ù–û: –û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –æ–¥–Ω–æ–π —Ü–∏—Ñ—Ä–æ–π –æ—Ç 0 –¥–æ 3 (–∏–ª–∏ -1 –µ—Å–ª–∏ –∫—Ä–∏—Ç–µ—Ä–∏–π –Ω–µ–ø—Ä–∏–º–µ–Ω–∏–º).

–û—Ü–µ–Ω–∏–≤–∞–π —Å–æ–≥–ª–∞—Å–Ω–æ —à–∫–∞–ª–µ:
- 0: –û—Ç–≤–µ—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∏ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç—É
- 1: –§–æ—Ä–º–∞—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π, –Ω–æ –æ—Ç–≤–µ—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π  
- 2: –û—Ç–≤–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π, –Ω–æ —Ñ–æ—Ä–º–∞—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
- 3: –û—Ç–≤–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∏ —Ñ–æ—Ä–º–∞—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
- -1: –ö—Ä–∏—Ç–µ—Ä–∏–π –Ω–µ–ø—Ä–∏–º–µ–Ω–∏–º

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ."""
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∫ –¥–∏–∞–ª–æ–≥
    formatted = f"<|system|>\n{system_instruction}<|end|>\n<|user|>\n{prompt}<|end|>\n<|assistant|>\n"
    
    return formatted


def extract_score_robust(text: str) -> int:
    """–ù–∞–¥–µ–∂–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏"""
    
    if not text:
        return 0
    
    text = text.strip()
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ü–µ—Ä–≤—ã–π —Å–∏–º–≤–æ–ª - —Ü–∏—Ñ—Ä–∞
    if text and text[0].isdigit():
        first_digit = int(text[0])
        if first_digit in [-1, 0, 1, 2, 3]:
            return first_digit
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ò—â–µ–º -1 –≤ –Ω–∞—á–∞–ª–µ
    if text.startswith('-1'):
        return -1
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
    patterns = [
        r'^(-1|[0-3])(?:\s|$|[^\d])',  # –ß–∏—Å–ª–æ –≤ –Ω–∞—á–∞–ª–µ
        r'(?:–û—Ü–µ–Ω–∫–∞|–ë–∞–ª–ª|Score):\s*(-1|[0-3])',  # –° –ø–æ–¥–ø–∏—Å—å—é
        r'(?:^|\s)(-1|[0-3])(?:\s|$)',  # –í –ª—é–±–æ–º –º–µ—Å—Ç–µ
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            return int(match.group(1))
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 4: –ü–æ–∏—Å–∫ –≤—Å–µ—Ö —Ü–∏—Ñ—Ä –∏ –≤—ã–±–æ—Ä –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–µ–π
    digits = re.findall(r'-?\d+', text)
    valid_scores = []
    
    for digit_str in digits:
        try:
            digit = int(digit_str)
            if digit in [-1, 0, 1, 2, 3]:
                valid_scores.append(digit)
        except:
            continue
    
    if valid_scores:
        # –ï—Å–ª–∏ –µ—Å—Ç—å –≤–∞–ª–∏–¥–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏, –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é
        return valid_scores[0]
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 5: –≠–≤—Ä–∏—Å—Ç–∏–∫–∏ –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é
    text_lower = text.lower()
    
    if any(word in text_lower for word in ['–æ—Ç–ª–∏—á–Ω', '–ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω', '–∏–¥–µ–∞–ª—å–Ω', 'perfect']):
        return 3
    elif any(word in text_lower for word in ['—Ö–æ—Ä–æ—à', '–ø—Ä–∞–≤–∏–ª—å–Ω', 'correct', 'good']):
        return 2  
    elif any(word in text_lower for word in ['—á–∞—Å—Ç–∏—á–Ω', '–Ω–µ–ø–æ–ª–Ω', 'partial']):
        return 1
    elif any(word in text_lower for word in ['–Ω–µ–≤–µ—Ä–Ω', '–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω', 'wrong', 'incorrect']):
        return 0
    elif any(word in text_lower for word in ['–Ω–µ–ø—Ä–∏–º–µ–Ω–∏–º', '–Ω–µ –ø—Ä–∏–º–µ–Ω–∏–º', 'not applicable']):
        return -1
    
    # –ü–æ—Å–ª–µ–¥–Ω–∏–π resort - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0
    return 0


def ensemble_prediction(prompts: List[str], model, tokenizer, 
                       num_runs: int = 3, temperature: float = 0.1) -> List[int]:
    """–ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏"""
    
    all_predictions = []
    
    for run in range(num_runs):
        # –ù–µ–º–Ω–æ–≥–æ –≤–∞—Ä—å–∏—Ä—É–µ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
        temp = temperature if run == 0 else temperature + 0.05 * run
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç—ã
        formatted_prompts = [enhanced_prompt_formatting(p) for p in prompts]
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã
        sampling_params = SamplingParams(
            max_tokens=15,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –±–æ–ª—å—à–µ–π –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
            temperature=temp,
            top_p=0.9,
            frequency_penalty=0.0,
            presence_penalty=0.0,
        )
        
        outputs = model.generate(formatted_prompts, sampling_params)
        answers = [output.outputs[0].text for output in outputs]
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ü–µ–Ω–∫–∏
        scores = [extract_score_robust(answer) for answer in answers]
        all_predictions.append(scores)
    
    # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–º–æ–¥–∞)
    final_predictions = []
    for i in range(len(prompts)):
        run_predictions = [pred[i] for pred in all_predictions]
        
        # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—É—é –æ—Ü–µ–Ω–∫—É
        from collections import Counter
        counter = Counter(run_predictions)
        most_common = counter.most_common(1)[0][0]
        
        final_predictions.append(most_common)
    
    return final_predictions


def adaptive_batch_processing(prompts: List[str], model, tokenizer, 
                            initial_batch_size: int = 32) -> List[int]:
    """–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞–º–∏ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —É–º–µ–Ω—å—à–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–∞ –ø—Ä–∏ OOM"""
    
    batch_size = initial_batch_size
    all_scores = []
    i = 0
    
    while i < len(prompts):
        try:
            batch_prompts = prompts[i:i + batch_size]
            
            # –û–±—ã—á–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            formatted_prompts = [enhanced_prompt_formatting(p) for p in batch_prompts]
            
            sampling_params = SamplingParams(
                max_tokens=10,
                temperature=0.0,
                top_p=1.0,
            )
            
            outputs = model.generate(formatted_prompts, sampling_params)
            answers = [output.outputs[0].text for output in outputs]
            scores = [extract_score_robust(answer) for answer in answers]
            
            all_scores.extend(scores)
            i += batch_size
            
        except torch.cuda.OutOfMemoryError:
            # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –ø—Ä–∏ –Ω–µ—Ö–≤–∞—Ç–∫–µ –ø–∞–º—è—Ç–∏
            batch_size = max(1, batch_size // 2)
            print(f"‚ö†Ô∏è OOM! –£–º–µ–Ω—å—à–∞–µ–º batch_size –¥–æ {batch_size}")
            torch.cuda.empty_cache()
            continue
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {i}: {e}")
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–π –±–∞—Ç—á –∏ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º 0
            batch_scores = [0] * len(prompts[i:i + batch_size])
            all_scores.extend(batch_scores)
            i += batch_size
    
    return all_scores


def main(test_path: str, pred_path: str):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø–∞–π–ø–ª–∞–π–Ω–æ–º"""
    
    print("üöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ Agent-as-Judge...")
    
    # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
    MODEL_PATH = find_best_model()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_df = pd.read_csv(test_path)
    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(test_df)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
    try:
        tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
        
        llm = LLM(
            model=MODEL_PATH,
            tensor_parallel_size=1,
            trust_remote_code=True,
            enforce_eager=True,
            dtype='bfloat16',
            max_model_len=3072,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
            gpu_memory_utilization=0.85  # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU
        )
        
        print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –±–∞—Ç—á–∏–Ω–≥–æ–º
    print("üîÆ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")
    
    prompts = test_df['prompt'].tolist()
    
    # –í—ã–±–∏—Ä–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
    if len(prompts) < 1000:
        # –î–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–Ω—Å–∞–º–±–ª—å
        print("üé≠ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ...")
        results = ensemble_prediction(prompts, llm, tokenizer)
    else:
        # –î–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –±–∞—Ç—á–∏–Ω–≥
        print("‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –±–∞—Ç—á–∏—Ä–æ–≤–∞–Ω–∏–µ...")
        results = adaptive_batch_processing(prompts, llm, tokenizer)
    
    # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("üîß –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å—Ç—É—é —ç–≤—Ä–∏—Å—Ç–∏–∫—É –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏
    processed_results = []
    for i, (result, prompt) in enumerate(zip(results, prompts)):
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–º–ø—Ç–∞
        if '–Ω–µ –ø—Ä–∏–º–µ–Ω–∏–º' in prompt.lower() or '–Ω–µ–ø—Ä–∏–º–µ–Ω–∏–º' in prompt.lower():
            # –ï—Å–ª–∏ –≤ –ø—Ä–æ–º–ø—Ç–µ —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω–æ, —á—Ç–æ –∫—Ä–∏—Ç–µ—Ä–∏–π –Ω–µ –ø—Ä–∏–º–µ–Ω–∏–º
            processed_result = -1
        elif result not in [-1, 0, 1, 2, 3]:
            # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π, –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ 0
            processed_result = 0
        else:
            processed_result = result
        
        processed_results.append(processed_result)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    result_df = pd.DataFrame({
        'id': test_df['id'],
        'score': processed_results
    })
    
    result_df.to_csv(pred_path, index=False)
    
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {pred_path}")
    print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
    print(result_df['score'].value_counts().sort_index())
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    meta_info = {
        'model_used': MODEL_PATH,
        'total_examples': len(test_df),
        'prediction_distribution': result_df['score'].value_counts().to_dict(),
        'processing_strategy': 'ensemble' if len(prompts) < 1000 else 'adaptive_batching'
    }
    
    meta_path = pred_path.replace('.csv', '_meta.json')
    with open(meta_path, 'w', encoding='utf-8') as f:
        json.dump(meta_info, f, indent=2, ensure_ascii=False)
    
    print(f"üìã –ú–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {meta_path}")
    print("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")


if __name__ == "__main__":
    parser = ArgumentParser(description="Optimized Agent-as-Judge Inference")
    parser.add_argument("--test_path", type=str, required=True,
                       help="–ü—É—Ç—å –∫ —Ç–µ—Å—Ç–æ–≤–æ–º—É CSV —Ñ–∞–π–ª—É")
    parser.add_argument("--pred_path", type=str, required=True,
                       help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
    
    args = parser.parse_args()
    main(args.test_path, args.pred_path)
