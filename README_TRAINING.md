# Agent-as-Judge Model Training ü§ñ‚öñÔ∏è

–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏-—Å—É–¥—å–∏ –≤ —Ä–∞–º–∫–∞—Ö —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è AI Journey.

## üìã –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏

–¶–µ–ª—å: –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –¥—Ä—É–≥–∏—Ö LLM –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º –∫–∞—á–µ—Å—Ç–≤–∞. –ú–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –≤—ã—Å—Ç–∞–≤–ª—è—Ç—å –æ—Ü–µ–Ω–∫–∏ –æ—Ç 0 –¥–æ 3 (–∏–ª–∏ -1 –µ—Å–ª–∏ –∫—Ä–∏—Ç–µ—Ä–∏–π –Ω–µ–ø—Ä–∏–º–µ–Ω–∏–º) –≤ —Ç—Ä–µ—Ö —Ç–∏–ø–∞—Ö –∑–∞–¥–∞—á:

1. **–°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –±–µ–Ω—á–º–∞—Ä–∫** - –∑–∞–¥–∞—á–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º
2. **Function Calling** - –æ—Ü–µ–Ω–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –≤—ã–∑–æ–≤–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π
3. **–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏** - –æ—Ç–∫—Ä—ã—Ç—ã–µ –∑–∞–¥–∞—á–∏ –±–µ–∑ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–µ—à–µ–Ω–∏—è

### –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
- **Qwen3-0.6B** - –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –æ—Ç Alibaba
- **Unsloth** - –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
- **LoRA/QLoRA** - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ñ–∞–π–Ω-—Ç—é–Ω–∏–Ω–≥ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏

### –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–±—É—á–µ–Ω–∏—è
1. **Baseline LoRA** - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥
2. **Balanced Classes** - –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
3. **Full Fine-tuning** - –ø–æ–ª–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (–ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤)
4. **Enhanced Config** - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã

## üìä –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö

**–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç**: 5,197 –ø—Ä–∏–º–µ—Ä–æ–≤
- 0 –±–∞–ª–ª–æ–≤: 1,445 –ø—Ä–∏–º–µ—Ä–æ–≤ (28%)
- 1 –±–∞–ª–ª: 1,911 –ø—Ä–∏–º–µ—Ä–æ–≤ (37%)
- 2 –±–∞–ª–ª–∞: 880 –ø—Ä–∏–º–µ—Ä–æ–≤ (17%) 
- 3 –±–∞–ª–ª–∞: 961 –ø—Ä–∏–º–µ—Ä–æ–≤ (18%)

**–¢–∏–ø—ã –∑–∞–¥–∞—á**:
- –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ: 1,531 (29%)
- –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ: 1,215 (23%)
- –ü—Ä–æ—á–∏–µ: 2,451 (47%)

## üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∑–∞–ø—É—Å–∫

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
```bash
# –û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install torch transformers datasets accelerate peft trl
pip install pandas numpy scikit-learn tqdm wandb

# Unsloth –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è  
pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"

# vLLM –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
pip install vllm

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
pip install xformers bitsandbytes triton
```

### –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

```bash
# 1. –ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ
python train_agent_judge.py --experiment 1

# 2. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
python train_agent_judge.py --experiment 2

# 3. –í—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å—Ä–∞–∑—É
python train_agent_judge.py --experiment all

# 4. –° –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≤ W&B
python train_agent_judge.py --experiment all --wandb_project "agent-judge-exp"
```

### –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã

```bash
# –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π –¥–∞–Ω–Ω—ã—Ö
python experiments_advanced.py

# Curriculum learning
python experiments_advanced.py --curriculum

# Ensemble –æ–±—É—á–µ–Ω–∏–µ
python experiments_advanced.py --ensemble
```

## üìà –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 1: Baseline LoRA
**–¶–µ–ª—å**: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–∞–∑–æ–≤—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è**:
- LoRA rank: 16
- Learning rate: 2e-4
- Epochs: 3
- Batch size: 4

**–û–∂–∏–¥–∞–µ–º—ã–µ —É–ª—É—á—à–µ–Ω–∏—è**: 
- –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- –•–æ—Ä–æ—à–∞—è –æ—Ç–ø—Ä–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞
- –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ø–∞–º—è—Ç–∏

### –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 2: Balanced Classes
**–¶–µ–ª—å**: –†–µ—à–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤
**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏**:
- Undersample/Oversample —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
- –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π LoRA rank: 32
- –ë–æ–ª—å—à–µ —ç–ø–æ—Ö: 4

**–û–∂–∏–¥–∞–µ–º—ã–µ —É–ª—É—á—à–µ–Ω–∏—è**:
- –õ—É—á—à–∏–π F1-score
- –ë–æ–ª–µ–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ –∫–ª–∞—Å—Å–∞–º

### –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 3: Full Fine-tuning
**–¶–µ–ª—å**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
**–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ**: ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ GPU –ø–∞–º—è—Ç–∏!
**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è**:
- –ü–æ–ª–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –≤–µ—Å–æ–≤
- –£–º–µ–Ω—å—à–µ–Ω–Ω—ã–π batch size
- Quantization –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ

### –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 4: Enhanced Configuration
**–¶–µ–ª—å**: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏**:
- LoRA rank: 64
- –£–≤–µ–ª–∏—á–µ–Ω–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: 3072
- –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ learning rate

## üîß –ò–Ω—Ñ–µ—Ä–µ–Ω—Å

### –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
```bash
python inference_agent_judge.py \
    --test_path test.csv \
    --pred_path predictions.csv \
    --model_path models/exp1_baseline_lora/unsloth_model
```

### –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
```bash
python run_optimized.py \
    --test_path test.csv \
    --pred_path predictions.csv
```

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞**:
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
- ‚úÖ –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –±–∞—Ç—á–∏—Ä–æ–≤–∞–Ω–∏–µ (–∏–∑–±–µ–≥–∞–µ—Ç OOM)
- ‚úÖ Ensemble –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- ‚úÖ –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- ‚úÖ Robust –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ –∏–∑ —Ç–µ–∫—Å—Ç–∞

## üìù –§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö

### –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (train)
```csv
id,prompt,score
abc123,"### –ó–∞–¥–∞–Ω–∏–µ –¥–ª—è –æ—Ü–µ–Ω–∫–∏:\n...### –≠—Ç–∞–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç:\n...### –û—Ç–≤–µ—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏:\n...### –ö—Ä–∏—Ç–µ—Ä–∏–π –æ—Ü–µ–Ω–∫–∏:\n...### –®–∫–∞–ª–∞ –æ—Ü–µ–Ω–∏–≤–∞–Ω–∏—è –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—é:\n...",2
```

### –í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (predictions)
```csv  
id,score
abc123,2
def456,0
```

## üéØ –ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

### 1. –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç-–∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥
```python
system_prompt = """–¢—ã - –º–æ–¥–µ–ª—å-—Å—É–¥—å—è, –∫–æ—Ç–æ—Ä–∞—è –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ –¥—Ä—É–≥–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. 
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –≤—ã—Å—Ç–∞–≤—å –æ—Ü–µ–Ω–∫—É —Å–æ–≥–ª–∞—Å–Ω–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –∫—Ä–∏—Ç–µ—Ä–∏—é –∏ —à–∫–∞–ª–µ –æ—Ü–µ–Ω–∏–≤–∞–Ω–∏—è. 
–û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–º –æ—Ç 0 –¥–æ 3 (–∏–ª–∏ -1, –µ—Å–ª–∏ –∫—Ä–∏—Ç–µ—Ä–∏–π –Ω–µ –ø—Ä–∏–º–µ–Ω–∏–º)."""
```

### 2. Robust Score Extraction
–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ü–µ–Ω–∫–∏:
- –ü–µ—Ä–≤–∞—è —Ü–∏—Ñ—Ä–∞ –≤ –æ—Ç–≤–µ—Ç–µ
- –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è  
- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
- –≠–≤—Ä–∏—Å—Ç–∏–∫–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º

### 3. Adaptive Training
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ batch size –ø—Ä–∏ OOM
- Gradient checkpointing –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
- Mixed precision training

### 4. Data Augmentation
- –ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤
- –°–æ–∑–¥–∞–Ω–∏–µ hard negatives
- Curriculum learning –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

### W&B Integration
```bash
export WANDB_PROJECT="agent-judge-experiments"
python train_agent_judge.py --experiment all
```

**–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏**:
- Training/Validation Loss
- Accuracy by score class
- F1-score (macro/weighted)
- Learning rate schedule
- Memory usage

### Local Logging
–í—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç:
- `training_config.json` - –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
- `validation_report.json` - –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏  
- Model checkpoints
- Training logs

## üîÑ Pipeline –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

```bash
# 1. –û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
python train_agent_judge.py --experiment 4

# 2. –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ  
python inference_agent_judge.py --validate validation.csv

# 3. –§–∏–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
python run_optimized.py --test_path test.csv --pred_path submission.csv

# 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
python -c "
import pandas as pd
df = pd.read_csv('submission.csv')
print('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫:', df.score.value_counts().sort_index())
print('–í–∞–ª–∏–¥–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–æ–∫:', df.score.isin([-1,0,1,2,3]).all())
"
```

## ‚ö° –°–æ–≤–µ—Ç—ã –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

### –î–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ LoRA —Å rank 16-32
- –í–∫–ª—é—á–∏—Ç–µ gradient checkpointing
- –£–º–µ–Ω—å—à–∏—Ç–µ batch size, —É–≤–µ–ª–∏—á—å—Ç–µ gradient accumulation
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ 4-bit quantization

### –î–ª—è –º–æ—â–Ω—ã—Ö GPU
- –ü–æ–ø—Ä–æ–±—É–π—Ç–µ full fine-tuning
- –£–≤–µ–ª–∏—á—å—Ç–µ LoRA rank –¥–æ 128+
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª—å—à–∏–π batch size
- –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å ensemble

### –î–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
- –ë–∞–ª–∞–Ω—Å–∏—Ä—É–π—Ç–µ –∫–ª–∞—Å—Å—ã –≤ –¥–∞–Ω–Ω—ã—Ö
- –ü—Ä–∏–º–µ–Ω—è–π—Ç–µ data augmentation  
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ curriculum learning
- –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–π—Ç–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞

## üêõ Troubleshooting

### OutOfMemoryError
```bash
# –£–º–µ–Ω—å—à–∏—Ç—å batch size
export CUDA_VISIBLE_DEVICES=0
python train_agent_judge.py --experiment 1 # Baseline uses smaller config
```

### –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏
```bash
# –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
python train_agent_judge.py --experiment 2

# –ò–ª–∏ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
python train_agent_judge.py --experiment 4
```

### –ü—Ä–æ–±–ª–µ–º—ã —Å —É—Å—Ç–∞–Ω–æ–≤–∫–æ–π Unsloth
```bash
# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞
pip install --no-deps unsloth
# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Docker
docker pull unsloth/unsloth:latest
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [Unsloth Documentation](https://github.com/unslothai/unsloth)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [Qwen3 Model Card](https://huggingface.co/Qwen/Qwen3-0.6B)
- [vLLM Documentation](https://docs.vllm.ai/)

## ü§ù –í–∫–ª–∞–¥ –∏ —Ä–∞–∑–≤–∏—Ç–∏–µ

–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:
1. **Multi-task learning** - –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ—Ö —Ç–∏–ø–∞—Ö –∑–∞–¥–∞—á
2. **Knowledge distillation** - –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏—è –æ—Ç –±–æ–ª–µ–µ –∫—Ä—É–ø–Ω–æ–π –º–æ–¥–µ–ª–∏
3. **Active learning** - –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤  
4. **Cross-validation** - –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
5. **Hyperparameter optimization** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

---

**–£–¥–∞—á–∏ –≤ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–∏! üèÜ**
